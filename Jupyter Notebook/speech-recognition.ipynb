{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc4daf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "393de80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads training dataset from json file\n",
    "with open(\"data.json\", \"r\") as fp:\n",
    "    data = json.load(fp)\n",
    "\n",
    "X = np.array(data[\"MFCCs\"])\n",
    "y = np.array(data[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a49b9067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, validation, test split\n",
    "train_img, test_img, train_label, test_label = train_test_split(X, y, test_size=0.2)\n",
    "train_img, validation_img, train_label, validation_label = train_test_split(train_img, train_label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0037b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an axis to nd array\n",
    "train_img = train_img[..., np.newaxis]\n",
    "test_img = test_img[..., np.newaxis]\n",
    "validation_img = validation_img[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d09ddd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (train_img.shape[1], train_img.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edcaa715",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "#1st conv layer\n",
    "model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', input_shape=input_shape, kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2,2), padding='same'))\n",
    "\n",
    "# 2nd conv layer\n",
    "model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2,2), padding='same'))\n",
    "\n",
    "# 3rd conv layer\n",
    "model.add(tf.keras.layers.Conv2D(32, (2, 2), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D((2, 2), strides=(2,2), padding='same'))\n",
    "\n",
    "# flatten output and feed into dense layer\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "tf.keras.layers.Dropout(0.3)\n",
    "\n",
    "# softmax output layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fbdc5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "427/427 [==============================] - 20s 46ms/step - loss: 1.1565 - accuracy: 0.6326 - val_loss: 0.7568 - val_accuracy: 0.7607\n",
      "Epoch 2/25\n",
      "427/427 [==============================] - 20s 47ms/step - loss: 0.5479 - accuracy: 0.8461 - val_loss: 0.6419 - val_accuracy: 0.8150\n",
      "Epoch 3/25\n",
      "427/427 [==============================] - 21s 48ms/step - loss: 0.3999 - accuracy: 0.8938 - val_loss: 0.5396 - val_accuracy: 0.8513\n",
      "Epoch 4/25\n",
      "427/427 [==============================] - 21s 48ms/step - loss: 0.3408 - accuracy: 0.9128 - val_loss: 0.4413 - val_accuracy: 0.8806\n",
      "Epoch 5/25\n",
      "427/427 [==============================] - 22s 52ms/step - loss: 0.2989 - accuracy: 0.9269 - val_loss: 0.4538 - val_accuracy: 0.8757\n",
      "Epoch 6/25\n",
      "427/427 [==============================] - 21s 49ms/step - loss: 0.2702 - accuracy: 0.9357 - val_loss: 0.4642 - val_accuracy: 0.8733\n",
      "Epoch 7/25\n",
      "427/427 [==============================] - 20s 48ms/step - loss: 0.2477 - accuracy: 0.9404 - val_loss: 0.5137 - val_accuracy: 0.8686\n",
      "Epoch 8/25\n",
      "427/427 [==============================] - 21s 50ms/step - loss: 0.2360 - accuracy: 0.9430 - val_loss: 0.4313 - val_accuracy: 0.8944\n",
      "Epoch 9/25\n",
      "427/427 [==============================] - 21s 50ms/step - loss: 0.2249 - accuracy: 0.9497 - val_loss: 0.3974 - val_accuracy: 0.9023\n",
      "Epoch 10/25\n",
      "427/427 [==============================] - 20s 47ms/step - loss: 0.2078 - accuracy: 0.9530 - val_loss: 0.4334 - val_accuracy: 0.8897\n",
      "Epoch 11/25\n",
      "427/427 [==============================] - 22s 52ms/step - loss: 0.2108 - accuracy: 0.9518 - val_loss: 0.3701 - val_accuracy: 0.9076\n",
      "Epoch 12/25\n",
      "427/427 [==============================] - 23s 53ms/step - loss: 0.1863 - accuracy: 0.9613 - val_loss: 0.4104 - val_accuracy: 0.9067\n",
      "Epoch 13/25\n",
      "427/427 [==============================] - 23s 53ms/step - loss: 0.1835 - accuracy: 0.9625 - val_loss: 0.3955 - val_accuracy: 0.9126\n",
      "Epoch 14/25\n",
      "427/427 [==============================] - 23s 54ms/step - loss: 0.1755 - accuracy: 0.9644 - val_loss: 0.4341 - val_accuracy: 0.8959\n",
      "Epoch 15/25\n",
      "427/427 [==============================] - 23s 53ms/step - loss: 0.1670 - accuracy: 0.9677 - val_loss: 0.4089 - val_accuracy: 0.9082\n",
      "Epoch 16/25\n",
      "427/427 [==============================] - 23s 55ms/step - loss: 0.1588 - accuracy: 0.9677 - val_loss: 0.4138 - val_accuracy: 0.9088\n",
      "Epoch 17/25\n",
      "427/427 [==============================] - 23s 55ms/step - loss: 0.1659 - accuracy: 0.9666 - val_loss: 0.5751 - val_accuracy: 0.8636\n",
      "Epoch 18/25\n",
      "427/427 [==============================] - 23s 54ms/step - loss: 0.1575 - accuracy: 0.9688 - val_loss: 0.3986 - val_accuracy: 0.9100\n",
      "Epoch 19/25\n",
      "427/427 [==============================] - 24s 55ms/step - loss: 0.1458 - accuracy: 0.9751 - val_loss: 0.5105 - val_accuracy: 0.8871\n",
      "Epoch 20/25\n",
      "427/427 [==============================] - 22s 52ms/step - loss: 0.1410 - accuracy: 0.9746 - val_loss: 0.4229 - val_accuracy: 0.9109\n",
      "Epoch 21/25\n",
      "427/427 [==============================] - 21s 49ms/step - loss: 0.1494 - accuracy: 0.9720 - val_loss: 0.5656 - val_accuracy: 0.8760\n",
      "Epoch 22/25\n",
      "427/427 [==============================] - 21s 50ms/step - loss: 0.1336 - accuracy: 0.9787 - val_loss: 0.4371 - val_accuracy: 0.9062\n",
      "Epoch 23/25\n",
      "427/427 [==============================] - 21s 50ms/step - loss: 0.1416 - accuracy: 0.9742 - val_loss: 0.4783 - val_accuracy: 0.8947\n",
      "Epoch 24/25\n",
      "427/427 [==============================] - 21s 50ms/step - loss: 0.1274 - accuracy: 0.9799 - val_loss: 0.4369 - val_accuracy: 0.9053\n",
      "Epoch 25/25\n",
      "427/427 [==============================] - 21s 50ms/step - loss: 0.1177 - accuracy: 0.9839 - val_loss: 0.4772 - val_accuracy: 0.9070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2ce0fea59d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "#train the model\n",
    "model.fit(train_img, train_label, epochs=25 , validation_data=(validation_img, validation_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f022c50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 1s 7ms/step - loss: 0.4404 - accuracy: 0.9109\n",
      "loss:  0.4404069483280182\n",
      "accuracy:  0.9108608961105347\n"
     ]
    }
   ],
   "source": [
    "# evaluate network on test set\n",
    "test_loss, test_acc = model.evaluate(test_img, test_label)\n",
    "print(\"loss: \" , test_loss)\n",
    "print(\"accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a27a2795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make prediction\n",
    "file_path = \"left.wav\"\n",
    "signal, sample_rate = librosa.load(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91f0c0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES_TO_CONSIDER = 22050 #samples in 1 sec\n",
    "if len(signal) >= SAMPLES_TO_CONSIDER:\n",
    "            # ensure consistency of the length of the signal\n",
    "            signal = signal[:SAMPLES_TO_CONSIDER]\n",
    "\n",
    "            # extract MFCCs\n",
    "            MFCCs = librosa.feature.mfcc(signal, sample_rate)\n",
    "            \n",
    "MGCCs = MFCCs.T\n",
    "\n",
    "# we need a 4-dim array to feed to the model for prediction: (# samples, # time steps, # coefficients, 1)\n",
    "MFCCs = MFCCs[np.newaxis, ..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcca41df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['down' 'go' 'left' 'no' 'off' 'on' 'right' 'stop' 'up' 'yes']\n"
     ]
    }
   ],
   "source": [
    "mapping = np.array(data[\"mapping\"])\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "352bfc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 44, 20, 1) for input Tensor(\"conv2d_input:0\", shape=(None, 44, 20, 1), dtype=float32), but it was called on an input with incompatible shape (None, 20, 44, 1).\n",
      "[9.9976069e-01 4.0300108e-08 5.6684885e-28 2.3875410e-04 1.3880232e-25\n",
      " 2.8547601e-18 5.8229201e-26 5.5689486e-07 9.4601727e-37 2.5568176e-23]\n",
      "down\n"
     ]
    }
   ],
   "source": [
    "# get the predicted label\n",
    "predictions = model.predict(MFCCs)[0]\n",
    "print(predictions)\n",
    "predicted_index = np.argmax(predictions)\n",
    "predicted_keyword = mapping[predicted_index]\n",
    "print(predicted_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94f9f0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'down': 99.98, 'go': 0.0, 'left': 0.0, 'no': 0.02, 'off': 0.0, 'on': 0.0, 'right': 0.0, 'stop': 0.0, 'up': 0.0, 'yes': 0.0}\n"
     ]
    }
   ],
   "source": [
    "res = {mapping[i]: round(predictions[i]*100,2) for i in range(len(mapping))}\n",
    "print(str(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9729b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"speech_test/down.wav\"\n",
    "signal, sample_rate = librosa.load(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf95b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES_TO_CONSIDER = 22050 #samples in 1 sec\n",
    "if len(signal) >= SAMPLES_TO_CONSIDER:\n",
    "            # ensure consistency of the length of the signal\n",
    "            signal = signal[:SAMPLES_TO_CONSIDER]\n",
    "           # extract MFCCs\n",
    "MFCCs = librosa.feature.mfcc(signal, sample_rate)\n",
    "            \n",
    "MGCCs = MFCCs.T\n",
    "\n",
    "# we need a 4-dim array to feed to the model for prediction: (# samples, # time steps, # coefficients, 1)\n",
    "MFCCs = MFCCs[np.newaxis, ..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bc21b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0000000e+00 5.3615449e-16 1.0775522e-37 1.5427034e-08 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 9.8093265e-21 0.0000000e+00 1.7638609e-37]\n",
      "down\n"
     ]
    }
   ],
   "source": [
    "# get the predicted label\n",
    "predictions = model.predict(MFCCs)[0]\n",
    "print(predictions)\n",
    "predicted_index = np.argmax(predictions)\n",
    "predicted_keyword = mapping[predicted_index]\n",
    "print(predicted_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5267fe4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'down': 100.0, 'go': 0.0, 'left': 0.0, 'no': 0.0, 'off': 0.0, 'on': 0.0, 'right': 0.0, 'stop': 0.0, 'up': 0.0, 'yes': 0.0}\n"
     ]
    }
   ],
   "source": [
    "res = {mapping[i]: round(predictions[i]*100,2) for i in range(len(mapping))}\n",
    "print(str(res))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
