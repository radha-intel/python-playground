{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc4daf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "393de80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads training dataset from json file\n",
    "with open(\"data.json\", \"r\") as fp:\n",
    "    data = json.load(fp)\n",
    "\n",
    "X = np.array(data[\"MFCCs\"])\n",
    "y = np.array(data[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a49b9067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, validation, test split\n",
    "\n",
    "train_img, test_img, train_label, test_label = train_test_split(X, y, test_size=0.2)\n",
    "train_img, validation_img, train_label, validation_label = train_test_split(train_img, train_label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0037b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an axis to nd array\n",
    "train_img = train_img[..., np.newaxis]\n",
    "test_img = test_img[..., np.newaxis]\n",
    "validation_img = validation_img[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d09ddd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(44, 20, 1)\n"
     ]
    }
   ],
   "source": [
    "input_shape = (train_img.shape[1], train_img.shape[2], 1)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe339709",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation=\"relu\", input_shape=input_shape))\n",
    "model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2,2), padding='same'))\n",
    "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D((3, 3), strides=(2,2), padding='same'))\n",
    "model.add(tf.keras.layers.Conv2D(128, kernel_size=(3,3), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.4))\n",
    "model.add(tf.keras.layers.Dense(10,activation=\"softmax\"))\n",
    "# print model parameters on console\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fbdc5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "427/427 [==============================] - 12s 29ms/step - loss: 1.9565 - accuracy: 0.3021 - val_loss: 1.2525 - val_accuracy: 0.5399\n",
      "Epoch 2/30\n",
      "427/427 [==============================] - 14s 32ms/step - loss: 1.0425 - accuracy: 0.6246 - val_loss: 0.6579 - val_accuracy: 0.7804\n",
      "Epoch 3/30\n",
      "427/427 [==============================] - 13s 31ms/step - loss: 0.6710 - accuracy: 0.7701 - val_loss: 0.4705 - val_accuracy: 0.8425\n",
      "Epoch 4/30\n",
      "427/427 [==============================] - 13s 32ms/step - loss: 0.5223 - accuracy: 0.8258 - val_loss: 0.3753 - val_accuracy: 0.8739\n",
      "Epoch 5/30\n",
      "427/427 [==============================] - 14s 32ms/step - loss: 0.4295 - accuracy: 0.8581 - val_loss: 0.3629 - val_accuracy: 0.8789\n",
      "Epoch 6/30\n",
      "427/427 [==============================] - 14s 32ms/step - loss: 0.3750 - accuracy: 0.8778 - val_loss: 0.4268 - val_accuracy: 0.8604\n",
      "Epoch 7/30\n",
      "427/427 [==============================] - 13s 32ms/step - loss: 0.3256 - accuracy: 0.8924 - val_loss: 0.3340 - val_accuracy: 0.8880\n",
      "Epoch 8/30\n",
      "427/427 [==============================] - 14s 32ms/step - loss: 0.3045 - accuracy: 0.9021 - val_loss: 0.3305 - val_accuracy: 0.8979\n",
      "Epoch 9/30\n",
      "427/427 [==============================] - 14s 33ms/step - loss: 0.2723 - accuracy: 0.9123 - val_loss: 0.3101 - val_accuracy: 0.8968\n",
      "Epoch 10/30\n",
      "427/427 [==============================] - 13s 32ms/step - loss: 0.2535 - accuracy: 0.9160 - val_loss: 0.3431 - val_accuracy: 0.8930\n",
      "Epoch 11/30\n",
      "427/427 [==============================] - 13s 31ms/step - loss: 0.2594 - accuracy: 0.9189 - val_loss: 0.3641 - val_accuracy: 0.8903\n",
      "Epoch 12/30\n",
      "427/427 [==============================] - 13s 31ms/step - loss: 0.2284 - accuracy: 0.9281 - val_loss: 0.3544 - val_accuracy: 0.9026\n",
      "Epoch 13/30\n",
      "427/427 [==============================] - 13s 31ms/step - loss: 0.2060 - accuracy: 0.9329 - val_loss: 0.4080 - val_accuracy: 0.8877\n",
      "Epoch 14/30\n",
      "427/427 [==============================] - 14s 32ms/step - loss: 0.2022 - accuracy: 0.9353 - val_loss: 0.2930 - val_accuracy: 0.9202\n",
      "Epoch 15/30\n",
      "427/427 [==============================] - 14s 32ms/step - loss: 0.1950 - accuracy: 0.9378 - val_loss: 0.3316 - val_accuracy: 0.9059\n",
      "Epoch 16/30\n",
      "427/427 [==============================] - 14s 32ms/step - loss: 0.1845 - accuracy: 0.9402 - val_loss: 0.2918 - val_accuracy: 0.9205\n",
      "Epoch 17/30\n",
      "427/427 [==============================] - 14s 32ms/step - loss: 0.1820 - accuracy: 0.9422 - val_loss: 0.2806 - val_accuracy: 0.9238\n",
      "Epoch 18/30\n",
      "427/427 [==============================] - 14s 32ms/step - loss: 0.1758 - accuracy: 0.9447 - val_loss: 0.3936 - val_accuracy: 0.9053\n",
      "Epoch 19/30\n",
      "427/427 [==============================] - 14s 32ms/step - loss: 0.1670 - accuracy: 0.9463 - val_loss: 0.3437 - val_accuracy: 0.9129\n",
      "Epoch 20/30\n",
      "427/427 [==============================] - 13s 32ms/step - loss: 0.1679 - accuracy: 0.9471 - val_loss: 0.3200 - val_accuracy: 0.9217\n",
      "Epoch 21/30\n",
      "427/427 [==============================] - 14s 32ms/step - loss: 0.1608 - accuracy: 0.9486 - val_loss: 0.3560 - val_accuracy: 0.9082\n",
      "Epoch 22/30\n",
      "427/427 [==============================] - 13s 31ms/step - loss: 0.1373 - accuracy: 0.9559 - val_loss: 0.3233 - val_accuracy: 0.9194\n",
      "Epoch 23/30\n",
      "427/427 [==============================] - 14s 32ms/step - loss: 0.1405 - accuracy: 0.9554 - val_loss: 0.3245 - val_accuracy: 0.9185\n",
      "Epoch 24/30\n",
      "427/427 [==============================] - 13s 31ms/step - loss: 0.1416 - accuracy: 0.9564 - val_loss: 0.3555 - val_accuracy: 0.9155\n",
      "Epoch 25/30\n",
      "427/427 [==============================] - 14s 32ms/step - loss: 0.1354 - accuracy: 0.9573 - val_loss: 0.2890 - val_accuracy: 0.9293\n",
      "Epoch 26/30\n",
      "427/427 [==============================] - 14s 33ms/step - loss: 0.1304 - accuracy: 0.9586 - val_loss: 0.3319 - val_accuracy: 0.9261\n",
      "Epoch 27/30\n",
      "427/427 [==============================] - 14s 32ms/step - loss: 0.1204 - accuracy: 0.9609 - val_loss: 0.3681 - val_accuracy: 0.9240\n",
      "Epoch 28/30\n",
      "427/427 [==============================] - 13s 31ms/step - loss: 0.1238 - accuracy: 0.9618 - val_loss: 0.3676 - val_accuracy: 0.9264\n",
      "Epoch 29/30\n",
      "427/427 [==============================] - 13s 31ms/step - loss: 0.1246 - accuracy: 0.9608 - val_loss: 0.3947 - val_accuracy: 0.9132\n",
      "Epoch 30/30\n",
      "427/427 [==============================] - 13s 31ms/step - loss: 0.1117 - accuracy: 0.9636 - val_loss: 0.4070 - val_accuracy: 0.9185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2a7b59862b0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "#train the model\n",
    "model.fit(train_img, train_label, epochs=30 , validation_data=(validation_img, validation_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f022c50a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 1s 8ms/step - loss: 0.3576 - accuracy: 0.9217\n",
      "loss:  0.3576222360134125\n",
      "accuracy:  0.9216514229774475\n"
     ]
    }
   ],
   "source": [
    "# evaluate network on test set\n",
    "test_loss, test_acc = model.evaluate(test_img, test_label)\n",
    "print(\"loss: \" , test_loss)\n",
    "print(\"accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcca41df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['down' 'go' 'left' 'no' 'off' 'on' 'right' 'stop' 'up' 'yes']\n"
     ]
    }
   ],
   "source": [
    "mapping = np.array(data[\"mapping\"])\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a94b6a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech_test/down.wav\n",
      "{'down': 0.0, 'go': 0.0, 'left': 0.0, 'no': 0.0, 'off': 0.0, 'on': 0.0, 'right': 0.0, 'stop': 100.0, 'up': 0.0, 'yes': 0.0}\n",
      "predicted keyword:  stop\n",
      "\n",
      "\n",
      "speech_test/go.wav\n",
      "{'down': 100.0, 'go': 0.0, 'left': 0.0, 'no': 0.0, 'off': 0.0, 'on': 0.0, 'right': 0.0, 'stop': 0.0, 'up': 0.0, 'yes': 0.0}\n",
      "predicted keyword:  down\n",
      "\n",
      "\n",
      "speech_test/left.wav\n",
      "{'down': 99.56, 'go': 0.18, 'left': 0.0, 'no': 0.02, 'off': 0.0, 'on': 0.0, 'right': 0.0, 'stop': 0.24, 'up': 0.0, 'yes': 0.0}\n",
      "predicted keyword:  down\n",
      "\n",
      "\n",
      "speech_test/no.wav\n",
      "{'down': 97.74, 'go': 0.27, 'left': 0.0, 'no': 1.97, 'off': 0.0, 'on': 0.0, 'right': 0.0, 'stop': 0.02, 'up': 0.0, 'yes': 0.0}\n",
      "predicted keyword:  down\n",
      "\n",
      "\n",
      "speech_test/off.wav\n",
      "{'down': 0.0, 'go': 0.0, 'left': 0.0, 'no': 0.0, 'off': 0.17, 'on': 0.0, 'right': 0.0, 'stop': 99.83, 'up': 0.0, 'yes': 0.0}\n",
      "predicted keyword:  stop\n",
      "\n",
      "\n",
      "speech_test/on.wav\n",
      "{'down': 0.0, 'go': 0.02, 'left': 0.0, 'no': 0.0, 'off': 0.0, 'on': 0.0, 'right': 0.0, 'stop': 0.62, 'up': 99.36, 'yes': 0.0}\n",
      "predicted keyword:  up\n",
      "\n",
      "\n",
      "speech_test/right.wav\n",
      "{'down': 99.82, 'go': 0.18, 'left': 0.0, 'no': 0.0, 'off': 0.0, 'on': 0.0, 'right': 0.0, 'stop': 0.0, 'up': 0.0, 'yes': 0.0}\n",
      "predicted keyword:  down\n",
      "\n",
      "\n",
      "speech_test/silent.wav\n",
      "{'down': 0.0, 'go': 0.0, 'left': 0.0, 'no': 0.0, 'off': 100.0, 'on': 0.0, 'right': 0.0, 'stop': 0.0, 'up': 0.0, 'yes': 0.0}\n",
      "predicted keyword:  off\n",
      "\n",
      "\n",
      "speech_test/stop.wav\n",
      "{'down': 0.0, 'go': 99.94, 'left': 0.0, 'no': 0.05, 'off': 0.0, 'on': 0.0, 'right': 0.0, 'stop': 0.0, 'up': 0.0, 'yes': 0.0}\n",
      "predicted keyword:  go\n",
      "\n",
      "\n",
      "speech_test/up.wav\n",
      "{'down': 0.0, 'go': 79.61, 'left': 0.0, 'no': 0.0, 'off': 0.0, 'on': 0.0, 'right': 0.0, 'stop': 5.48, 'up': 14.9, 'yes': 0.0}\n",
      "predicted keyword:  go\n",
      "\n",
      "\n",
      "speech_test/yes.wav\n",
      "{'down': 0.0, 'go': 0.81, 'left': 0.0, 'no': 0.03, 'off': 0.0, 'on': 99.15, 'right': 0.02, 'stop': 0.0, 'up': 0.0, 'yes': 0.0}\n",
      "predicted keyword:  on\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SAMPLES_TO_CONSIDER = 22050 #samples in 1 sec\n",
    "path = \"speech_test\"\n",
    "for i in os.listdir(path):\n",
    "    #file_path = \"speech_test/off.wav\"\n",
    "    signal, sample_rate = librosa.load(path+ '//' +i)\n",
    "    print(path+'/'+i)\n",
    "    if len(signal) >= SAMPLES_TO_CONSIDER:\n",
    "            # ensure consistency of the length of the signal\n",
    "            signal = signal[:SAMPLES_TO_CONSIDER]\n",
    "           # extract MFCCs\n",
    "    MFCCs = librosa.feature.mfcc(signal, sample_rate)\n",
    "    MFCCs = MFCCs.reshape(44,20)        \n",
    "    # we need a 4-dim array to feed to the model for prediction: (# samples, # time steps, # coefficients, 1)\n",
    "    MFCCs = MFCCs[np.newaxis, ... , np.newaxis]\n",
    "\n",
    "    # get the predicted label\n",
    "    predictions = model.predict(MFCCs)[0]\n",
    "    #print(predictions)\n",
    "    res = {mapping[i]: round(predictions[i]*100,2) for i in range(len(mapping))}\n",
    "    print(str(res))\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    predicted_keyword = mapping[predicted_index]\n",
    "    print(\"predicted keyword: \", predicted_keyword)\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
