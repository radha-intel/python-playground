{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc4daf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "393de80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads training dataset from json file\n",
    "with open(\"data.json\", \"r\") as fp:\n",
    "    data = json.load(fp)\n",
    "\n",
    "X = np.array(data[\"MFCCs\"])\n",
    "y = np.array(data[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a49b9067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train, validation, test split\n",
    "train_img, test_img, train_label, test_label = train_test_split(X, y, test_size=0.2)\n",
    "train_img, validation_img, train_label, validation_label = train_test_split(train_img, train_label, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0037b5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add an axis to nd array\n",
    "train_img = train_img[..., np.newaxis]\n",
    "test_img = test_img[..., np.newaxis]\n",
    "validation_img = validation_img[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d09ddd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (train_img.shape[1], train_img.shape[2], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73602da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation=\"relu\", input_shape=input_shape))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1,1), padding='same'))\n",
    "model.add(tf.keras.layers.Conv2D(64, kernel_size=(3,3), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Conv2D(128, kernel_size=(3,3), activation=\"relu\"))\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(tf.keras.layers.Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(64, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.25))\n",
    "model.add(tf.keras.layers.Dense(32, activation=\"relu\"))\n",
    "model.add(tf.keras.layers.Dropout(0.3))\n",
    "model.add(tf.keras.layers.Dense(10,activation=\"softmax\"))\n",
    "# print model parameters on console\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fbdc5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "427/427 [==============================] - 39s 91ms/step - loss: 1.9467 - accuracy: 0.2782 - val_loss: 1.2154 - val_accuracy: 0.5452\n",
      "Epoch 2/10\n",
      "427/427 [==============================] - 38s 88ms/step - loss: 1.1655 - accuracy: 0.5573 - val_loss: 0.8244 - val_accuracy: 0.7023\n",
      "Epoch 3/10\n",
      "427/427 [==============================] - 38s 89ms/step - loss: 0.7979 - accuracy: 0.7162 - val_loss: 0.5307 - val_accuracy: 0.8176\n",
      "Epoch 4/10\n",
      "427/427 [==============================] - 38s 89ms/step - loss: 0.5936 - accuracy: 0.7987 - val_loss: 0.4373 - val_accuracy: 0.8572\n",
      "Epoch 5/10\n",
      "427/427 [==============================] - 38s 90ms/step - loss: 0.4660 - accuracy: 0.8490 - val_loss: 0.4896 - val_accuracy: 0.8440\n",
      "Epoch 6/10\n",
      "427/427 [==============================] - 39s 91ms/step - loss: 0.3982 - accuracy: 0.8731 - val_loss: 0.3700 - val_accuracy: 0.8804\n",
      "Epoch 7/10\n",
      "427/427 [==============================] - 38s 88ms/step - loss: 0.3497 - accuracy: 0.8940 - val_loss: 0.4211 - val_accuracy: 0.8777\n",
      "Epoch 8/10\n",
      "427/427 [==============================] - 38s 89ms/step - loss: 0.2933 - accuracy: 0.9114 - val_loss: 0.3696 - val_accuracy: 0.8974\n",
      "Epoch 9/10\n",
      "427/427 [==============================] - 39s 91ms/step - loss: 0.2763 - accuracy: 0.9131 - val_loss: 0.3836 - val_accuracy: 0.9062\n",
      "Epoch 10/10\n",
      "427/427 [==============================] - 38s 88ms/step - loss: 0.2374 - accuracy: 0.9277 - val_loss: 0.3546 - val_accuracy: 0.9073\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1a189c1fd00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile model\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "#train the model\n",
    "model.fit(train_img, train_label, epochs=10 , validation_data=(validation_img, validation_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f022c50a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 3s 21ms/step - loss: 0.3058 - accuracy: 0.9167\n",
      "loss:  0.3057601749897003\n",
      "accuracy:  0.9167253375053406\n"
     ]
    }
   ],
   "source": [
    "# evaluate network on test set\n",
    "test_loss, test_acc = model.evaluate(test_img, test_label)\n",
    "print(\"loss: \" , test_loss)\n",
    "print(\"accuracy: \", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a27a2795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make prediction\n",
    "file_path = \"up.wav\"\n",
    "signal, sample_rate = librosa.load(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91f0c0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES_TO_CONSIDER = 22050 #samples in 1 sec\n",
    "if len(signal) >= SAMPLES_TO_CONSIDER:\n",
    "            # ensure consistency of the length of the signal\n",
    "            signal = signal[:SAMPLES_TO_CONSIDER]\n",
    "\n",
    "            # extract MFCCs\n",
    "            MFCCs = librosa.feature.mfcc(signal, sample_rate)\n",
    "            \n",
    "MGCCs = MFCCs.T\n",
    "\n",
    "# we need a 4-dim array to feed to the model for prediction: (# samples, # time steps, # coefficients, 1)\n",
    "MFCCs = MFCCs[np.newaxis, ..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcca41df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['down' 'go' 'left' 'no' 'off' 'on' 'right' 'stop' 'up' 'yes']\n"
     ]
    }
   ],
   "source": [
    "mapping = np.array(data[\"mapping\"])\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "352bfc5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 44, 20, 1) for input Tensor(\"conv2d_input:0\", shape=(None, 44, 20, 1), dtype=float32), but it was called on an input with incompatible shape (None, 20, 44, 1).\n",
      "[8.41170400e-02 1.69087184e-06 3.84402949e-15 1.14383267e-10\n",
      " 1.28914740e-10 9.15866077e-01 5.50265172e-12 1.48137133e-05\n",
      " 3.15191841e-07 1.09869884e-13]\n",
      "on\n"
     ]
    }
   ],
   "source": [
    "# get the predicted label\n",
    "predictions = model.predict(MFCCs)[0]\n",
    "print(predictions)\n",
    "predicted_index = np.argmax(predictions)\n",
    "predicted_keyword = mapping[predicted_index]\n",
    "print(predicted_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94f9f0c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'down': 8.41, 'go': 0.0, 'left': 0.0, 'no': 0.0, 'off': 0.0, 'on': 91.59, 'right': 0.0, 'stop': 0.0, 'up': 0.0, 'yes': 0.0}\n"
     ]
    }
   ],
   "source": [
    "res = {mapping[i]: round(predictions[i]*100,2) for i in range(len(mapping))}\n",
    "print(str(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9729b21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"speech_test/off.wav\"\n",
    "signal, sample_rate = librosa.load(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bf95b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLES_TO_CONSIDER = 22050 #samples in 1 sec\n",
    "if len(signal) >= SAMPLES_TO_CONSIDER:\n",
    "            # ensure consistency of the length of the signal\n",
    "            signal = signal[:SAMPLES_TO_CONSIDER]\n",
    "           # extract MFCCs\n",
    "MFCCs = librosa.feature.mfcc(signal, sample_rate)\n",
    "            \n",
    "MGCCs = MFCCs.T\n",
    "\n",
    "# we need a 4-dim array to feed to the model for prediction: (# samples, # time steps, # coefficients, 1)\n",
    "MFCCs = MFCCs[np.newaxis, ..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8bc21b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.3704596e-04 4.6765595e-06 4.5452747e-13 2.0949321e-10 1.0525706e-06\n",
      " 9.9965239e-01 2.6351923e-10 1.0062279e-06 3.9269908e-06 4.2629064e-14]\n",
      "on\n"
     ]
    }
   ],
   "source": [
    "# get the predicted label\n",
    "predictions = model.predict(MFCCs)[0]\n",
    "print(predictions)\n",
    "predicted_index = np.argmax(predictions)\n",
    "predicted_keyword = mapping[predicted_index]\n",
    "print(predicted_keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "90be91b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'down': 0.03, 'go': 0.0, 'left': 0.0, 'no': 0.0, 'off': 0.0, 'on': 99.97, 'right': 0.0, 'stop': 0.0, 'up': 0.0, 'yes': 0.0}\n"
     ]
    }
   ],
   "source": [
    "res = {mapping[i]: round(predictions[i]*100,2) for i in range(len(mapping))}\n",
    "print(str(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b1244364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech_test/down.wav\n",
      "{'down': 99.65, 'go': 0.02, 'left': 0.0, 'no': 0.0, 'off': 0.0, 'on': 0.3, 'right': 0.0, 'stop': 0.02, 'up': 0.0, 'yes': 0.0}\n",
      "predicted keyword:  down\n",
      "\n",
      "\n",
      "speech_test/go.wav\n",
      "{'down': 3.4, 'go': 0.19, 'left': 0.0, 'no': 0.0, 'off': 0.0, 'on': 96.35, 'right': 0.0, 'stop': 0.03, 'up': 0.03, 'yes': 0.0}\n",
      "predicted keyword:  on\n",
      "\n",
      "\n",
      "speech_test/left.wav\n",
      "{'down': 0.06, 'go': 99.78, 'left': 0.0, 'no': 0.16, 'off': 0.0, 'on': 0.0, 'right': 0.0, 'stop': 0.0, 'up': 0.0, 'yes': 0.0}\n",
      "predicted keyword:  go\n",
      "\n",
      "\n",
      "speech_test/no.wav\n",
      "{'down': 0.55, 'go': 31.07, 'left': 5.52, 'no': 16.69, 'off': 9.89, 'on': 0.56, 'right': 0.2, 'stop': 1.11, 'up': 34.17, 'yes': 0.23}\n",
      "predicted keyword:  up\n",
      "\n",
      "\n",
      "speech_test/off.wav\n",
      "{'down': 0.03, 'go': 0.0, 'left': 0.0, 'no': 0.0, 'off': 0.0, 'on': 99.97, 'right': 0.0, 'stop': 0.0, 'up': 0.0, 'yes': 0.0}\n",
      "predicted keyword:  on\n",
      "\n",
      "\n",
      "speech_test/on.wav\n",
      "{'down': 21.51, 'go': 3.67, 'left': 0.0, 'no': 0.22, 'off': 0.1, 'on': 69.22, 'right': 0.01, 'stop': 0.14, 'up': 5.13, 'yes': 0.0}\n",
      "predicted keyword:  on\n",
      "\n",
      "\n",
      "speech_test/right.wav\n",
      "{'down': 0.05, 'go': 0.0, 'left': 0.0, 'no': 0.0, 'off': 0.0, 'on': 99.95, 'right': 0.0, 'stop': 0.0, 'up': 0.0, 'yes': 0.0}\n",
      "predicted keyword:  on\n",
      "\n",
      "\n",
      "speech_test/silent.wav\n",
      "{'down': 99.59, 'go': 0.08, 'left': 0.0, 'no': 0.0, 'off': 0.0, 'on': 0.34, 'right': 0.0, 'stop': 0.0, 'up': 0.0, 'yes': 0.0}\n",
      "predicted keyword:  down\n",
      "\n",
      "\n",
      "speech_test/stop.wav\n",
      "{'down': 1.67, 'go': 0.0, 'left': 0.0, 'no': 0.0, 'off': 0.0, 'on': 98.33, 'right': 0.0, 'stop': 0.0, 'up': 0.0, 'yes': 0.0}\n",
      "predicted keyword:  on\n",
      "\n",
      "\n",
      "speech_test/up.wav\n",
      "{'down': 8.41, 'go': 0.0, 'left': 0.0, 'no': 0.0, 'off': 0.0, 'on': 91.59, 'right': 0.0, 'stop': 0.0, 'up': 0.0, 'yes': 0.0}\n",
      "predicted keyword:  on\n",
      "\n",
      "\n",
      "speech_test/yes.wav\n",
      "{'down': 71.1, 'go': 26.39, 'left': 0.0, 'no': 0.76, 'off': 0.0, 'on': 1.1, 'right': 0.01, 'stop': 0.36, 'up': 0.26, 'yes': 0.0}\n",
      "predicted keyword:  down\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SAMPLES_TO_CONSIDER = 22050 #samples in 1 sec\n",
    "path = \"speech_test\"\n",
    "for i in os.listdir(path):\n",
    "    #file_path = \"speech_test/off.wav\"\n",
    "    signal, sample_rate = librosa.load(path+ '//' +i)\n",
    "    print(path+'/'+i)\n",
    "    if len(signal) >= SAMPLES_TO_CONSIDER:\n",
    "            # ensure consistency of the length of the signal\n",
    "            signal = signal[:SAMPLES_TO_CONSIDER]\n",
    "           # extract MFCCs\n",
    "    MFCCs = librosa.feature.mfcc(signal, sample_rate)\n",
    "            \n",
    "    MGCCs = MFCCs.T\n",
    "\n",
    "    # we need a 4-dim array to feed to the model for prediction: (# samples, # time steps, # coefficients, 1)\n",
    "    MFCCs = MFCCs[np.newaxis, ..., np.newaxis]\n",
    "    # get the predicted label\n",
    "    predictions = model.predict(MFCCs)[0]\n",
    "    #print(predictions)\n",
    "    res = {mapping[i]: round(predictions[i]*100,2) for i in range(len(mapping))}\n",
    "    print(str(res))\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    predicted_keyword = mapping[predicted_index]\n",
    "    print(\"predicted keyword: \", predicted_keyword)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f88e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
