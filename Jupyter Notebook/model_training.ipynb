{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90c86f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "import io\n",
    "import sys\n",
    "import librosa\n",
    "import os.path\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "from tensorflow.keras.models import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.utils import *\n",
    "from tensorflow.keras import backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d36d53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveModel(model, file):\n",
    "    model.save(file)\n",
    "    print('Saved model to disk.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63e25c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadModel(file):\n",
    "    print('Loading model from disk.')\n",
    "    return load_model(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7e30581",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelExist(model):\n",
    "    file = Path(model)\n",
    "    if file.is_file():\n",
    "        print('Model file exist.')\n",
    "    else:\n",
    "        print('Model file not found.')\n",
    "    return file.is_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d3232a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_dim_convolution_model_for_multi_class(width, height, channel, nClasses):\n",
    "    inputShape = (width, height, channel)\n",
    "    print('inputshape', inputShape)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (2, 2), input_shape=inputShape,\n",
    "                     data_format='channels_last'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(64, (2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Conv2D(128, (2, 2)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(Dense(128))\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(nClasses))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    print(model.summary())\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e197d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio2mfcc(audioData, maxPadLen):\n",
    "    # code: if you pass the filepath\n",
    "    # audio, sr = librosa.load(filePath, mono=True, sr=None)\n",
    "\n",
    "    data = io.BytesIO(audioData)\n",
    "    audio, sr = sf.read(data)\n",
    "\n",
    "    # output generated from target has some noise for first 3ms\n",
    "    # skip read first 3ms, if the file' sample rate is > 16000\n",
    "    if (sr > 16000):\n",
    "        adata = io.BytesIO(audioData)\n",
    "        audio, sr = sf.read(adata, start=14400)\n",
    "\n",
    "    # Reading audio files using PySoundFile is similmar to the method in librosa.\n",
    "    # One important difference is that the read data is of shape (nb_samples, nb_channels) compared to (nb_channels, nb_samples) in <librosa.core.load>.\n",
    "    audio = audio.T\n",
    "\n",
    "    # Force an audio signal down to mono\n",
    "    audio = librosa.to_mono(audio)\n",
    "\n",
    "    # Resample a time series from orig_sr to target_sr\n",
    "    audio = librosa.resample(audio, sr, 16000)\n",
    "\n",
    "    #sf.write('sample_output.wav', audio, 16000, 'PCM_16')\n",
    "\n",
    "    #cutshort the training time\n",
    "    #audio = audio[::3]\n",
    "\n",
    "    mfcc = librosa.feature.mfcc(audio, sr=16000)\n",
    "    padWidth = maxPadLen - mfcc.shape[1]\n",
    "    mfcc = np.pad(mfcc, pad_width=((0, 0), (0, padWidth)), mode='constant')\n",
    "    return mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "882fc01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "featureWidth = 20\n",
    "featureHeight = 300\n",
    "featureChannel = 1\n",
    "nClasses = 11\n",
    "epochs = 10\n",
    "batchSize = 100\n",
    "verbose = 1\n",
    "\n",
    "datasetPath = 'dataset2'\n",
    "modelFile = 'waves.hdf5'\n",
    "\n",
    "def generateTrainTestData(path=datasetPath, testSize=0.30):\n",
    "    #get labels\n",
    "    labels = os.listdir(path)\n",
    "    labels = [x.split('.')[0] for x in labels]\n",
    "    print('tLabels', labels)\n",
    "\n",
    "    binaryLabelPath = path + '/' + labels[0] + '.npy'\n",
    "    tData = np.load(binaryLabelPath)\n",
    "    tLabel = np.zeros(tData.shape[0])\n",
    "    \n",
    "    trainData, testData, trainLabel, testLabel = train_test_split(tData, tLabel, test_size=testSize, shuffle=True)\n",
    "\n",
    "    print('trainData shape', trainData.shape)\n",
    "    print('trainLabel shape', trainLabel.shape)\n",
    "    print('testData shape', testData.shape)\n",
    "    print('testLabel shape', testLabel.shape)\n",
    "\n",
    "    for i, label in enumerate(labels[1:]):\n",
    "\n",
    "        if (label == '_background_noise_'):\n",
    "            print('skipping bg noise label')\n",
    "            continue\n",
    "\n",
    "        binaryLabelPath = path + '/' + label + '.npy'\n",
    "        x = np.load(binaryLabelPath)\n",
    "        y = np.full(x.shape[0], fill_value=(i + 1))\n",
    "        temp_trainData, temp_testData, temp_trainLabel, temp_testLabel = train_test_split(x, y, test_size=testSize, shuffle=True)\n",
    "        print('temp_trainData shape', temp_trainData.shape)\n",
    "        print('temp_trainLabel shape', temp_trainLabel.shape)\n",
    "        print('temp_testData shape', temp_testData.shape)\n",
    "        print('temp_testLabel shape', temp_testLabel.shape)\n",
    "        trainData = np.vstack((trainData, temp_trainData))\n",
    "        testData = np.vstack((testData, temp_testData))\n",
    "        trainLabel = np.append(trainLabel,temp_trainLabel)\n",
    "        testLabel = np.append(testLabel,temp_testLabel)\n",
    "        \n",
    "        \n",
    "        #tData = np.vstack((tData, x))\n",
    "        #tLabel = np.append(tLabel, np.full(x.shape[0], fill_value=(i + 1)))\n",
    "\n",
    "    print('trainData shape', trainData.shape)\n",
    "    print('trainLabel shape', trainLabel.shape)\n",
    "    print('testData shape', testData.shape)\n",
    "    print('testLabel shape\\n', testLabel.shape)\n",
    "    #print('tData shape', tData.shape)\n",
    "    #print('tLabel shape', tLabel.shape)\n",
    "    return trainData, testData, trainLabel, testLabel\n",
    "\n",
    "\n",
    "checkpoint = [\n",
    "    ModelCheckpoint(filepath=modelFile, verbose=1,\n",
    "                    monitor='val_acc', save_best_only=True),\n",
    "    EarlyStopping(monitor='val_acc', min_delta=0,\n",
    "                  patience=100, verbose=1, mode='auto')\n",
    "]\n",
    "\n",
    "def trainModel(model, trainData, trainLabelHot, testData, testLabelHot, epochs=epochs, verbose=verbose, batchSize=batchSize):\n",
    "    return model.fit(\n",
    "        trainData, trainLabelHot,\n",
    "        batch_size=batchSize,\n",
    "        epochs=epochs,\n",
    "        verbose=verbose,\n",
    "        validation_data=(testData, testLabelHot),\n",
    "        callbacks=checkpoint)\n",
    "\n",
    "def waves_training():\n",
    "    if (modelExist(modelFile)):\n",
    "        print('Waves model file exist in disk.')\n",
    "        return loadModel(modelFile)\n",
    "    else:\n",
    "        # generate train test data\n",
    "        trainData, testData, trainLabel, testLabel = generateTrainTestData()\n",
    "\n",
    "        # One hot encoding\n",
    "        trainLabelHot = to_categorical(trainLabel)\n",
    "        testLabelHot = to_categorical(testLabel)\n",
    "\n",
    "        # Reshaping to perform 2D convolution\n",
    "        trainData = trainData.reshape(\n",
    "            trainData.shape[0], featureWidth, featureHeight, featureChannel)\n",
    "        testData = testData.reshape(\n",
    "            testData.shape[0], featureWidth, featureHeight, featureChannel)\n",
    "\n",
    "        # build model\n",
    "        model = two_dim_convolution_model_for_multi_class(featureWidth, featureHeight, featureChannel, nClasses)\n",
    "\n",
    "        # train\n",
    "        trainModel(model, trainData, trainLabelHot, testData, testLabelHot)\n",
    "\n",
    "        #save model\n",
    "        saveModel(model, modelFile)\n",
    "\n",
    "        return loadModel(modelFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5538830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model file not found.\n",
      "tLabels ['down', 'go', 'left', 'no', 'noise', 'off', 'on', 'right', 'stop', 'up', 'yes']\n",
      "trainData shape (1652, 20, 300)\n",
      "trainLabel shape (1652,)\n",
      "testData shape (708, 20, 300)\n",
      "testLabel shape (708,)\n",
      "temp_trainData shape (1661, 20, 300)\n",
      "temp_trainLabel shape (1661,)\n",
      "temp_testData shape (712, 20, 300)\n",
      "temp_testLabel shape (712,)\n",
      "temp_trainData shape (1647, 20, 300)\n",
      "temp_trainLabel shape (1647,)\n",
      "temp_testData shape (707, 20, 300)\n",
      "temp_testLabel shape (707,)\n",
      "temp_trainData shape (1663, 20, 300)\n",
      "temp_trainLabel shape (1663,)\n",
      "temp_testData shape (713, 20, 300)\n",
      "temp_testLabel shape (713,)\n",
      "temp_trainData shape (21, 20, 300)\n",
      "temp_trainLabel shape (21,)\n",
      "temp_testData shape (9, 20, 300)\n",
      "temp_testLabel shape (9,)\n",
      "temp_trainData shape (1650, 20, 300)\n",
      "temp_trainLabel shape (1650,)\n",
      "temp_testData shape (708, 20, 300)\n",
      "temp_testLabel shape (708,)\n",
      "temp_trainData shape (1657, 20, 300)\n",
      "temp_trainLabel shape (1657,)\n",
      "temp_testData shape (711, 20, 300)\n",
      "temp_testLabel shape (711,)\n",
      "temp_trainData shape (1657, 20, 300)\n",
      "temp_trainLabel shape (1657,)\n",
      "temp_testData shape (711, 20, 300)\n",
      "temp_testLabel shape (711,)\n",
      "temp_trainData shape (1666, 20, 300)\n",
      "temp_trainLabel shape (1666,)\n",
      "temp_testData shape (715, 20, 300)\n",
      "temp_testLabel shape (715,)\n",
      "temp_trainData shape (1663, 20, 300)\n",
      "temp_trainLabel shape (1663,)\n",
      "temp_testData shape (713, 20, 300)\n",
      "temp_testLabel shape (713,)\n",
      "temp_trainData shape (1664, 20, 300)\n",
      "temp_trainLabel shape (1664,)\n",
      "temp_testData shape (714, 20, 300)\n",
      "temp_testLabel shape (714,)\n",
      "trainData shape (16601, 20, 300)\n",
      "trainLabel shape (16601,)\n",
      "testData shape (7121, 20, 300)\n",
      "testLabel shape\n",
      " (7121,)\n",
      "inputshape (20, 300, 1)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 19, 299, 32)       160       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 19, 299, 32)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 18, 298, 64)       8256      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 18, 298, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 17, 297, 128)      32896     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 17, 297, 128)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 8, 148, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 8, 148, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 151552)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               19398784  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 11)                715       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 11)                0         \n",
      "=================================================================\n",
      "Total params: 19,449,067\n",
      "Trainable params: 19,449,067\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "167/167 [==============================] - ETA: 0s - loss: 2.2968 - accuracy: 0.1393WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "167/167 [==============================] - 288s 2s/step - loss: 2.2968 - accuracy: 0.1393 - val_loss: 2.3434 - val_accuracy: 0.1623\n",
      "Epoch 2/10\n",
      "167/167 [==============================] - ETA: 0s - loss: 2.0297 - accuracy: 0.2493WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "167/167 [==============================] - 295s 2s/step - loss: 2.0297 - accuracy: 0.2493 - val_loss: 1.9628 - val_accuracy: 0.2841\n",
      "Epoch 3/10\n",
      "167/167 [==============================] - ETA: 0s - loss: 1.7212 - accuracy: 0.3756WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "167/167 [==============================] - 306s 2s/step - loss: 1.7212 - accuracy: 0.3756 - val_loss: 1.9499 - val_accuracy: 0.3035\n",
      "Epoch 4/10\n",
      "167/167 [==============================] - ETA: 0s - loss: 1.4578 - accuracy: 0.4818WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "167/167 [==============================] - 300s 2s/step - loss: 1.4578 - accuracy: 0.4818 - val_loss: 1.7897 - val_accuracy: 0.3971\n",
      "Epoch 5/10\n",
      "167/167 [==============================] - ETA: 0s - loss: 1.1593 - accuracy: 0.5931WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "167/167 [==============================] - 301s 2s/step - loss: 1.1593 - accuracy: 0.5931 - val_loss: 1.9900 - val_accuracy: 0.3553\n",
      "Epoch 6/10\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.9240 - accuracy: 0.6750WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "167/167 [==============================] - 298s 2s/step - loss: 0.9240 - accuracy: 0.6750 - val_loss: 2.1112 - val_accuracy: 0.3928\n",
      "Epoch 7/10\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.7805 - accuracy: 0.7322WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "167/167 [==============================] - 300s 2s/step - loss: 0.7805 - accuracy: 0.7322 - val_loss: 2.3906 - val_accuracy: 0.3731\n",
      "Epoch 8/10\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.6626 - accuracy: 0.7742WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "167/167 [==============================] - 322s 2s/step - loss: 0.6626 - accuracy: 0.7742 - val_loss: 2.9164 - val_accuracy: 0.3624\n",
      "Epoch 9/10\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.6668 - accuracy: 0.7735WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "167/167 [==============================] - 372s 2s/step - loss: 0.6668 - accuracy: 0.7735 - val_loss: 2.9207 - val_accuracy: 0.3848\n",
      "Epoch 10/10\n",
      "167/167 [==============================] - ETA: 0s - loss: 0.5167 - accuracy: 0.8265WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
      "167/167 [==============================] - 385s 2s/step - loss: 0.5167 - accuracy: 0.8265 - val_loss: 2.9011 - val_accuracy: 0.3915\n",
      "Saved model to disk.\n",
      "Loading model from disk.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x20e03939ee0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waves_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403be8f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
